# type: ignore
import json
import os
import re
from datetime import datetime

from bs4 import BeautifulSoup
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# ğŸ”§ ì„¤ì • ì˜ì—­
sheets_json_key_path = "/Users/kdkyu311/Downloads/gst-manegemnet-70faf8ce1bff.json"
html_file_path = "/Users/kdkyu311/Desktop/GST/í˜‘ë ¥ì‚¬/index_06.13.html"
DRIVE_FOLDER_ID = "13FdsniLHb4qKmn5M4-75H8SvgEyW2Ck1"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if not os.path.exists(sheets_json_key_path):
    raise FileNotFoundError(f"JSON í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {sheets_json_key_path}")
if not os.path.exists(html_file_path):
    raise FileNotFoundError(f"HTML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {html_file_path}")

# ğŸ” ì¸ì¦ ë° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
credentials = Credentials.from_service_account_file(sheets_json_key_path, scopes=SCOPES)
drive_service = build("drive", "v3", credentials=credentials)

# ğŸ§¾ HTML ë¡œë“œ
with open(html_file_path, "r", encoding="utf-8") as f:
    soup = BeautifulSoup(f.read(), "html.parser")

# ğŸ•’ ì‹¤í–‰ ì‹œê°„ íŒŒì‹±
execution_tag = soup.find("p", string=re.compile("ğŸ“… ì‹¤í–‰ ì‹œê°„"))
if not execution_tag:
    raise ValueError("ì‹¤í–‰ ì‹œê°„ íƒœê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
exec_time_match = re.search(r"\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}", execution_tag.text)
if not exec_time_match:
    raise ValueError(f"ì‹¤í–‰ ì‹œê°„ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤: {execution_tag.text}")
exec_time = exec_time_match.group()
execution_time = exec_time.replace("-", "").replace(" ", "_").replace(":", "")
exec_dt = datetime.strptime(exec_time, "%Y-%m-%d %H:%M:%S")
weekday_kor = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][exec_dt.weekday()]
session = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5}.get(exec_dt.weekday(), 0)
filename = f"nan_ot_results_{execution_time}_{weekday_kor}_{session}íšŒì°¨.json"

# ğŸ“¦ JSON êµ¬ì¡° ì´ˆê¸°í™”
json_data = {"execution_time": execution_time, "results": []}

# ğŸ“Š ìš”ì•½ í…Œì´ë¸” ì¶”ì¶œ
table = soup.find("table", id="summaryTable")
if not table:
    raise ValueError("í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
rows = table.find_all("tr")
if len(rows) < 2:
    raise ValueError("í…Œì´ë¸”ì— ë°ì´í„° í–‰ì´ ì—†ìŠµë‹ˆë‹¤.")

# í—¤ë” ì°¾ê¸°: ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ê°„ì£¼
header_row = rows[0]
header_cells = header_row.find_all("th")
if not header_cells:
    print("í…Œì´ë¸” ì²« 5í–‰ êµ¬ì¡°:")
    for i, row in enumerate(rows[:5]):
        cells = row.find_all(["th", "td"])
        cell_texts = [cell.get_text().strip() for cell in cells]
        print(f"í–‰ {i}: {cell_texts}")
    raise ValueError("í—¤ë” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…Œì´ë¸” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

# í—¤ë” í…ìŠ¤íŠ¸ ì¶”ì¶œ: data-column ì†ì„± ìš°ì„  ì‚¬ìš©
headers = []
for cell in header_cells:
    # data-column ì†ì„± ì‚¬ìš©
    header_name = cell.get("data-column", "")
    if not header_name:
        # ëŒ€ì²´ë¡œ í…ìŠ¤íŠ¸ ì‚¬ìš©, <select> íƒœê·¸ ì œì™¸
        for select in cell.find_all("select"):
            select.decompose()
        header_name = cell.get_text(separator=" ").strip().split(" ")[0]
    headers.append(header_name)

# í•„ë“œ ë§¤í•‘
field_map = {
    "order_no": "Order",
    "model_name": "ëª¨ë¸ëª…",
    "mech_partner": "ê¸°êµ¬í˜‘ë ¥ì‚¬",
    "elec_partner": "ì „ì¥í˜‘ë ¥ì‚¬",
    "total_tasks": ["ì´ ì‘ì—… ìˆ˜", "ì´"],  # "ì´" í—ˆìš©
}
field_indices = {}
for key, expected in field_map.items():
    if isinstance(expected, list):
        for idx, h in enumerate(headers):
            if any(h.lower().strip() == e.lower().strip() for e in expected):
                field_indices[key] = idx
                break
    else:
        for idx, h in enumerate(headers):
            if h.lower().strip() == expected.lower().strip():
                field_indices[key] = idx
                break
if len(field_indices) < len(field_map):
    print(f"í—¤ë”: {headers}")
    raise ValueError(f"ì¼ë¶€ í•„ìš”í•œ í•„ë“œê°€ í—¤ë”ì— ì—†ìŠµë‹ˆë‹¤. ë°œê²¬ëœ í•„ë“œ: {field_indices}")

# ë°ì´í„° í–‰ ì²˜ë¦¬: í—¤ë” í–‰ ì´í›„
data_rows = []
for row in rows[1:]:
    cells = row.find_all("td")
    if cells and len(cells) >= len(headers):
        order_no_cell = cells[field_indices["order_no"]]
        order_no = order_no_cell.get_text().strip()
        # ì£¼ë¬¸ ë²ˆí˜¸ í˜•ì‹(/ í¬í•¨) í™•ì¸
        if order_no and "/" in order_no:
            data_rows.append(row)

for row in data_rows:
    cols = row.find_all("td")
    order_no_cell = cols[field_indices["order_no"]]
    order_no = order_no_cell.get_text().strip()
    # í•˜ì´í¼ë§í¬ ì¶”ì¶œ
    order_link = order_no_cell.find("a")
    order_href = order_link["href"] if order_link else ""

    try:
        total_tasks = int(cols[field_indices["total_tasks"]].get_text().strip())
    except ValueError:
        continue  # ìˆ«ìë¡œ ë³€í™˜ ë¶ˆê°€ ì‹œ ê±´ë„ˆë›°ê¸°

    json_data["results"].append(
        {
            "order_no": order_no,
            "model_name": cols[field_indices["model_name"]].get_text().strip(),
            "mech_partner": cols[field_indices["mech_partner"]].get_text().strip(),
            "elec_partner": cols[field_indices["elec_partner"]].get_text().strip(),
            "total_tasks": total_tasks,
            "ratios": {},
            "links": {"order_href": order_href},
        }
    )

# ğŸ“‹ ìƒì„¸ ë°ì´í„° íŒŒì‹±
categories = ["ê¸°êµ¬", "TMS_ë°˜ì œí’ˆ", "ì „ì¥", "ê²€ì‚¬", "ë§ˆë¬´ë¦¬", "ê¸°íƒ€"]
details_tags = soup.find_all("details")

for detail in details_tags:
    summary = detail.find("summary")
    if not summary:
        continue

    # order_no ì¶”ì¶œ
    order_match = re.search(r"Order: (.+?),", summary.get_text())
    if not order_match:
        continue
    order_no = order_match.group(1).strip()

    result = next((r for r in json_data["results"] if r["order_no"] == order_no), None)
    if not result:
        continue

    occurrence_stats = {}
    partner_stats = {"mech": {"nan_count": 0, "ot_count": 0}, "elec": {"nan_count": 0, "ot_count": 0}}
    ratios = {}

    for category in categories:
        p_tag = next((p for p in detail.find_all("p") if f"ğŸ”¹ {category} ì‘ì—…" in p.get_text()), None)
        if not p_tag:
            occurrence_stats[category] = {"total_count": 0, "nan_count": 0, "ot_count": 0}
            continue
        text = p_tag.get_text(separator="\n")
        total_match = re.search(r"ì „ì²´ ì‘ì—… ìˆ˜:\s*(\d+)", text)
        nan_match = re.search(r"ëˆ„ë½\(NaN\):\s*(\d+)", text)
        ot_match = re.search(r"ì˜¤ë²„íƒ€ì„:\s*(\d+)", text)
        total = int(total_match.group(1)) if total_match else 0
        nan = int(nan_match.group(1)) if nan_match else 0
        ot = int(ot_match.group(1)) if ot_match else 0
        occurrence_stats[category] = {"total_count": total, "nan_count": nan, "ot_count": ot}

        if category == "ê¸°êµ¬":
            partner_stats["mech"]["nan_count"] = nan
            partner_stats["mech"]["ot_count"] = ot
            ratios["mech_nan_ratio"] = nan / total * 100 if total else 0
            ratios["mech_ot_ratio"] = ot / total * 100 if total else 0
        elif category == "ì „ì¥":
            partner_stats["elec"]["nan_count"] = nan
            partner_stats["elec"]["ot_count"] = ot
            ratios["elec_nan_ratio"] = nan / total * 100 if total else 0
            ratios["elec_ot_ratio"] = ot / total * 100 if total else 0
        elif category == "TMS_ë°˜ì œí’ˆ":
            ratios["tms_nan_ratio"] = nan / total * 100 if total else 0
            ratios["tms_ot_ratio"] = ot / total * 100 if total else 0

    result["occurrence_stats"] = occurrence_stats
    result["partner_stats"] = partner_stats
    result["ratios"] = ratios
    result["spreadsheet_url"] = ""

# ğŸ’¾ JSON ì €ì¥
with open(filename, "w", encoding="utf-8") as f:
    json.dump(json_data, f, ensure_ascii=False, indent=2)
print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {filename}")

# â˜ï¸ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ
file_metadata = {"name": filename, "parents": [DRIVE_FOLDER_ID]}
media = MediaFileUpload(filename, mimetype="application/json")
uploaded = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
print(f"âœ… ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì™„ë£Œ: ID = {uploaded['id']}")

# ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì‚­ì œ
if os.path.exists(filename):
    os.remove(filename)
    print(f"ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {filename}")
else:
    print(f"âš ï¸ ì‚­ì œí•˜ë ¤ëŠ” íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {filename}")
