import json
import os
import re
from datetime import datetime, timedelta

import matplotlib.dates as mdates
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# ---------------------------
# 1. Google Drive API ì„¤ì •
# ---------------------------
sheets_json_key_path = "/Users/kdkyu311/Downloads/gst-manegemnet-70faf8ce1bff.json"
SCOPES = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
DRIVE_FOLDER_ID = "13FdsniLHb4qKmn5M4-75H8SvgEyW2Ck1"
credentials = Credentials.from_service_account_file(sheets_json_key_path, scopes=SCOPES)
drive_service = build("drive", "v3", credentials=credentials)

# ---------------------------
# 2. í°íŠ¸ ì„¤ì • (NanumGothic)
# ---------------------------
font_paths = [
    "/Users/kdkyu311/Library/Fonts/NanumGothic.ttf",
    "/System/Library/AssetsV2/com_apple_MobileAsset_Font7/bad9b4bf17cf1669dde54184ba4431c22dcad27b.asset/AssetData/NanumGothic.ttc",
    "/Library/Fonts/NanumGothic.ttf",
    "/System/Library/Fonts/Supplemental/NanumGothic.ttf",
]
font_path = next((path for path in font_paths if os.path.exists(path)), None)
if font_path:
    print(f"âœ… NanumGothic í°íŠ¸ ì ìš© ì™„ë£Œ: {font_path}")
    font_prop = fm.FontProperties(fname=font_path)
    plt.rc("font", family=font_prop.get_name())
else:
    print("ğŸš¨ NanumGothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
plt.rcParams["axes.unicode_minus"] = False


# ---------------------------
# 3. JSON íŒŒì¼ ë¡œë“œ í•¨ìˆ˜
# ---------------------------
def load_json_files_from_drive(week_number=None, friday_only=False):
    """Google Drive í´ë” ë‚´ JSON íŒŒì¼ ë¡œë“œ, week_number ë˜ëŠ” friday_onlyë¡œ í•„í„°ë§."""
    query = f"'{DRIVE_FOLDER_ID}' in parents and name contains 'nan_ot_results_'"
    if friday_only:
        query += " and name contains '_ê¸ˆ_'"
    files = drive_service.files().list(q=query, fields="files(id, name)").execute().get("files", [])
    data_list = []
    if not files:
        print("âš ï¸ ë¡œë“œí•  JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return data_list

    for file in files:
        file_name = file["name"]
        match = re.search(r"nan_ot_results_(\d{8})_", file_name)
        if not match:
            continue
        file_date = match.group(1)  # YYYYMMDD
        try:
            file_datetime = pd.to_datetime(file_date, format="%Y%m%d")
            file_week = file_datetime.isocalendar().week
        except ValueError:
            continue

        # week_number í•„í„°ë§
        if week_number is not None and file_week != week_number:
            continue

        print(f"ğŸ“ JSON íŒŒì¼ ë¡œë“œ ì¤‘: {file_name}")
        file_id = file["id"]
        request = drive_service.files().get_media(fileId=file_id)
        content = request.execute().decode("utf-8")
        data = json.loads(content)
        for result in data["results"]:
            result["execution_time"] = data["execution_time"]
        data_list.extend(data["results"])

    print(f"ğŸ“‚ ì´ {len(data_list)}ê°œì˜ ë¡œê·¸ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return data_list


def ratio_calc(stats):
    total = stats.get("total_count", 0)
    nan_count = stats.get("nan_count", 0)
    return (nan_count / total * 100) if total > 0 else 0


# ---------------------------
# 4. ìë™ ì£¼ê°„ ì •ë³´ ê³„ì‚° í•¨ìˆ˜
# ---------------------------
def auto_week_info():
    all_data = load_json_files_from_drive()  # ëª¨ë“  JSONìœ¼ë¡œ ì£¼ê°„ ì •ë³´ ê³„ì‚°
    if not all_data:
        print("âš ï¸ JSON ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    times = [pd.to_datetime(item["execution_time"], format="%Y%m%d_%H%M%S") for item in all_data]
    latest_date = max(times)
    week_number = latest_date.isocalendar().week
    start_date = latest_date - timedelta(days=latest_date.weekday())  # ì›”ìš”ì¼
    end_date = start_date + timedelta(days=4)  # ê¸ˆìš”ì¼
    print(f"ğŸ§  ìë™ ê³„ì‚° ì£¼ê°„ ì •ë³´: week_number={week_number}, date_range=({start_date.date()}, {end_date.date()})")
    return week_number, (start_date, end_date)


# ---------------------------
# 5. ì›”ê°„ ê·¸ë˜í”„ ìƒì„± ì¡°ê±´: ë§ˆì§€ë§‰ ì£¼ ê¸ˆìš”ì¼ ê°ì§€ í•¨ìˆ˜
# ---------------------------
def is_last_friday_in_month():
    all_data = load_json_files_from_drive(friday_only=True)
    if not all_data:
        return False
    df = pd.DataFrame(
        [
            {"execution_time": d["execution_time"], "date": pd.to_datetime(d["execution_time"], format="%Y%m%d_%H%M%S")}
            for d in all_data
        ]
    )
    df["month"] = df["date"].dt.month
    df["week"] = df["date"].dt.isocalendar().week
    df["weekday"] = df["date"].dt.weekday
    result = {}
    for month, group in df.groupby("month"):
        max_week = group["week"].max()
        last_week_data = group[group["week"] == max_week]
        result[month] = 4 in last_week_data["weekday"].values
    current_month = datetime.now().month
    return result.get(current_month, False)


# ---------------------------
# 6. ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜
# ---------------------------
def generate_nan_trend_graph(
    period="weekly",
    chart_type="stacked_bar",
    quarterly_targets=None,
    week_number=None,
    date_range=None,
    days_per_week="auto",
    group_by="partner",
):
    if quarterly_targets is None:
        quarterly_targets = {1: 40, 2: 30, 3: 20, 4: 0}

    # ì£¼ê°„: ì´ë²ˆ ì£¼ JSON, ì›”ê°„: ê¸ˆìš”ì¼ JSON
    load_week = week_number if period == "weekly" else None
    friday_only = period == "monthly"
    all_data = load_json_files_from_drive(week_number=load_week, friday_only=friday_only)
    if not all_data:
        print("âš ï¸ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    df_data = []
    for d in all_data:
        execution_time = d["execution_time"]
        occurrence_stats = d.get("occurrence_stats", {})
        mech_partner = d.get("mech_partner", "").strip().upper()
        elec_partner = d.get("elec_partner", "").strip().upper()
        entry = {
            "date": execution_time,
            "model_name": d["model_name"],
            "mech_partner": mech_partner,
            "elec_partner": elec_partner,
            "bat_nan_ratio": 0.0,
            "fni_nan_ratio": 0.0,
            "tms_m_nan_ratio": 0.0,
            "cna_nan_ratio": 0.0,
            "pns_nan_ratio": 0.0,
            "tms_e_nan_ratio": 0.0,
            "tms_semi_nan_ratio": 0.0,
        }
        if mech_partner == "BAT":
            target = occurrence_stats.get("ê¸°êµ¬", {})
            entry["bat_nan_ratio"] = ratio_calc(target)
        elif mech_partner == "FNI":
            target = occurrence_stats.get("ê¸°êµ¬", {})
            entry["fni_nan_ratio"] = ratio_calc(target)
        elif mech_partner == "TMS":
            target = occurrence_stats.get("ê¸°êµ¬", {})
            entry["tms_m_nan_ratio"] = ratio_calc(target)
        if elec_partner == "C&A":
            target = occurrence_stats.get("ì „ì¥", {})
            entry["cna_nan_ratio"] = ratio_calc(target)
        elif elec_partner == "P&S":
            target = occurrence_stats.get("ì „ì¥", {})
            entry["pns_nan_ratio"] = ratio_calc(target)
        elif elec_partner == "TMS":
            target = occurrence_stats.get("ì „ì¥", {})
            entry["tms_e_nan_ratio"] = ratio_calc(target)
        tms_semi_stats = occurrence_stats.get("TMS_ë°˜ì œí’ˆ", {})
        entry["tms_semi_nan_ratio"] = ratio_calc(tms_semi_stats)
        df_data.append(entry)

    df = pd.DataFrame(df_data)
    df["date"] = pd.to_datetime(df["date"], format="%Y%m%d_%H%M%S", errors="coerce")
    df = df.dropna(subset=["date"])
    df["quarter"] = df["date"].dt.quarter
    df["week"] = df["date"].dt.isocalendar().week

    if week_number is not None:
        df = df[df["week"] == week_number]
        if df.empty:
            print(f"âš ï¸ {week_number}ì£¼ì°¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    if date_range is not None:
        start_date, end_date = date_range
        start_date = pd.to_datetime(start_date)
        end_date = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
        df = df[(df["date"] >= start_date) & (df["date"] <= end_date)]
        if df.empty:
            print(f"âš ï¸ {start_date} ~ {end_date} ì‚¬ì´ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        else:
            print("ğŸ“… í¬í•¨ëœ ë‚ ì§œ:", df["date"].dt.date.unique())

    if period == "weekly":
        if days_per_week == "auto":
            unique_weekdays = set(df["date"].dt.weekday.unique())
            if set(range(5)).issubset(unique_weekdays):
                days_per_week = "5days"
            elif {0, 2, 4}.issubset(unique_weekdays) and len(unique_weekdays) == 3:
                days_per_week = "3days"
            else:
                days_per_week = "mixed"
            print(f"ğŸ§  ìë™ ê°ì§€ëœ days_per_week: {days_per_week}")
        if days_per_week == "3days":
            df = df[df["date"].dt.weekday.isin([0, 2, 4])]
        elif days_per_week == "5days":
            df = df[df["date"].dt.weekday.isin([0, 1, 2, 3, 4])]
        else:
            print("ğŸ§  mixed days_per_week: í•„í„° ë¯¸ì ìš©")

    if df.empty:
        print("âš ï¸ í•„í„°ë§ í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    partner_categories = [
        ("bat_nan_ratio", "BAT", "blue"),
        ("fni_nan_ratio", "FNI", "cyan"),
        ("tms_m_nan_ratio", "TMS(m)", "orange"),
        ("cna_nan_ratio", "C&A", "green"),
        ("pns_nan_ratio", "P&S", "red"),
        ("tms_e_nan_ratio", "TMS(e)", "purple"),
        ("tms_semi_nan_ratio", "TMS_ë°˜ì œí’ˆ", "magenta"),
    ]

    if period == "weekly":
        df = df.sort_values("date")
        df["day"] = df["date"].dt.date
        if group_by == "partner":
            df_grouped = df.groupby("day").mean(numeric_only=True)
        elif group_by == "model":
            df_grouped = df.groupby(["day", "model_name"]).mean(numeric_only=True).reset_index()
            categories = [
                (row["model_name"], row["model_name"], "blue")
                for _, row in df_grouped[["model_name"]].drop_duplicates().iterrows()
            ]
            df_grouped = df_grouped.pivot(
                index="day", columns="model_name", values=[col[0] for col in partner_categories]
            )
            df_grouped.columns = [col[1] for col in df_grouped.columns]
        else:
            raise ValueError("group_byëŠ” 'partner' ë˜ëŠ” 'model'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        labels = [f"{d.month}ì›”{d.day}ì¼" for d in df_grouped.index]
        title = f"ì£¼ê°„ NaN ë¹„ìœ¨ ì¶”ì´ ({days_per_week})"
        xlabel = "ì¸¡ì • ë‚ ì§œ"
    elif period == "monthly":
        if group_by == "partner":
            df_grouped = df.groupby(df["date"].dt.to_period("M")).mean(numeric_only=True)
            df_grouped.index = df_grouped.index.to_timestamp()
            categories = partner_categories
            labels = [d.strftime("%Y-%m") for d in df_grouped.index]
        elif group_by == "model":
            df_grouped = df.groupby([df["date"].dt.to_period("M"), "model_name"]).mean(numeric_only=True).reset_index()
            df_grouped["date"] = df_grouped["date"].apply(lambda x: x.to_timestamp())
            categories = [
                (row["model_name"], row["model_name"], "blue")
                for _, row in df_grouped[["model_name"]].drop_duplicates().iterrows()
            ]
            df_grouped = df_grouped.pivot(
                index="date", columns="model_name", values=[col[0] for col in partner_categories]
            )
            df_grouped.columns = [col[1] for col in df_grouped.columns]
            labels = [d.strftime("%Y-%m") for d in df_grouped.index]
        else:
            raise ValueError("group_byëŠ” 'partner' ë˜ëŠ” 'model'ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        title = "ì›”ê°„ NaN ë¹„ìœ¨ ì¶”ì´ (ê¸ˆìš”ì¼ ê¸°ì¤€)"
        xlabel = "ì›”"

    df_grouped["quarter"] = df_grouped.index.map(lambda x: pd.to_datetime(x).quarter)

    plt.figure(figsize=(12, 6))
    if chart_type == "heatmap":
        if group_by == "partner":
            heatmap_data = df_grouped[[cat[0] for cat in partner_categories]].T
            heatmap_data.index = [cat[1] for cat in partner_categories]
            y_label = "í˜‘ë ¥ì‚¬"
        else:
            heatmap_data = df_grouped.groupby(axis=1, level=0).mean().T
            y_label = "ëª¨ë¸"
        sns.heatmap(heatmap_data, annot=True, fmt=".1f", cmap="YlOrRd", cbar_kws={"label": "NaN ë¹„ìœ¨ (%)"})
        plt.title(title)
        plt.xlabel(xlabel)
        plt.ylabel(y_label)
        plt.xticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=45, ha="right")
        filename = f"{period}_{group_by}_nan_heatmap_{datetime.now().strftime('%Y%m%d')}.png"
        plt.savefig(filename, bbox_inches="tight")
        plt.close()
        print(f"âœ… NaN íˆíŠ¸ë§µ ìƒì„± ì™„ë£Œ: {filename}")
        return filename
    elif chart_type == "stacked_bar":
        bottom = np.zeros(len(df_grouped))
        for category, label, color in partner_categories:
            if category in df_grouped.columns:
                plt.bar(df_grouped.index, df_grouped[category], bottom=bottom, label=label, color=color)
                for i, (x, y) in enumerate(zip(df_grouped.index, df_grouped[category])):
                    if y >= 30:
                        plt.text(x, bottom[i] + y / 2, f"{y:.1f}%", ha="center", va="center", color="black")
                bottom += df_grouped[category].fillna(0)
        for quarter, target in quarterly_targets.items():
            valid_quarter = df_grouped["quarter"].dropna().unique()
            if quarter in valid_quarter:
                plt.axhline(y=target, color="black", linestyle="--", label=f"{quarter}ë¶„ê¸° ëª©í‘œ ({target}%)", alpha=0.5)
    else:
        for category, label, color in partner_categories:
            if category in df_grouped.columns:
                plt.plot(df_grouped.index, df_grouped[category], label=label, marker="o", color=color)
                for x, y in zip(df_grouped.index, df_grouped[category]):
                    if y >= 30:
                        plt.text(x, y, f"{y:.1f}%", ha="center", va="bottom", color=color)

    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel("NaN ë¹„ìœ¨ (%)")
    plt.legend()
    plt.grid(True)
    plt.ylim(0, 100)
    plt.xticks(ticks=np.arange(len(labels)) + 0.5, labels=labels, rotation=45, ha="right")
    filename = f"{period}_{group_by}_nan_trend_{chart_type}_{datetime.now().strftime('%Y%m%d')}.png"
    plt.savefig(filename, bbox_inches="tight")
    plt.close()
    print(f"âœ… NaN ì¶”ì´ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ: {filename}")
    return filename


# ---------------------------
# 7. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ í•¨ìˆ˜
# ---------------------------
def upload_to_drive(filename):
    file_metadata = {"name": filename, "parents": [DRIVE_FOLDER_ID]}
    media = MediaFileUpload(filename, mimetype="image/png")
    file = drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
    file_id = file.get("id")
    drive_service.permissions().create(fileId=file_id, body={"type": "anyone", "role": "reader"}).execute()
    image_url = f"https://drive.google.com/uc?export=view&id={file_id}"
    print(f"âœ… ê·¸ë˜í”„ íŒŒì¼ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—…ë¡œë“œ ì™„ë£Œ: {filename}, íŒŒì¼ ID: {file_id}")
    os.remove(filename)
    print(f"ğŸ—‘ï¸ ë¡œì»¬ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {filename}")
    return image_url


# ---------------------------
# 8. ìµœì¢… ì‹¤í–‰
# ---------------------------
if __name__ == "__main__":
    quarterly_targets = {1: 40, 2: 30, 3: 20, 4: 0}

    # ìë™ìœ¼ë¡œ ì£¼ê°„ ì •ë³´ ê³„ì‚°
    auto_week, auto_range = auto_week_info()
    if auto_week is None or auto_range is None:
        print("âš ï¸ ì£¼ê°„ ì •ë³´ ìë™ ê³„ì‚° ì‹¤íŒ¨")
    else:
        week_number = auto_week
        date_range = (auto_range[0].strftime("%Y-%m-%d"), auto_range[1].strftime("%Y-%m-%d"))

    # ì£¼ê°„ ê·¸ë˜í”„ (ì´ë²ˆ ì£¼ JSON, í˜‘ë ¥ì‚¬ ê¸°ì¤€, heatmap)
    weekly_partner_heatmap = generate_nan_trend_graph(
        period="weekly",
        chart_type="heatmap",
        quarterly_targets=quarterly_targets,
        week_number=week_number,
        date_range=date_range,
        days_per_week="auto",
        group_by="partner",
    )
    if weekly_partner_heatmap:
        weekly_partner_heatmap_link = upload_to_drive(weekly_partner_heatmap)

    # ì›”ê°„ ê·¸ë˜í”„ (ê¸ˆìš”ì¼ JSON, ë§ˆì§€ë§‰ ì£¼ ê¸ˆìš”ì¼ì—ë§Œ ìƒì„±)
    if is_last_friday_in_month():
        monthly_partner_heatmap = generate_nan_trend_graph(
            period="monthly", chart_type="heatmap", quarterly_targets=quarterly_targets, group_by="partner"
        )
        if monthly_partner_heatmap:
            monthly_partner_heatmap_link = upload_to_drive(monthly_partner_heatmap)

        monthly_model_heatmap = generate_nan_trend_graph(
            period="monthly", chart_type="heatmap", quarterly_targets=quarterly_targets, group_by="model"
        )
        if monthly_model_heatmap:
            monthly_model_heatmap_link = upload_to_drive(monthly_model_heatmap)
